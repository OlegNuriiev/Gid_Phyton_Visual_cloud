import csv
import requests
import ssl
from bs4 import BeautifulSoup
from urllib3 import poolmanager
from wrvwer import TLSAdapter


class SamplePars:
    def __init__(self, url, name, pagination_cd):
        self.url = url
        self.name = name
        self.CSV = str(self.name) + '.csv'
        self.pagination_cd = pagination_cd
        self.count = 0

    @staticmethod
    def get_html(url, params=None):
        session = requests.Session()
        headers = {
            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                          'Chrome/113.0.0.0 Safari/537.36',
            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,'
                      '*/*;q=0.8,application/signed-exchange;v=b3;q=0.7'}
        datas = {
            'email': 'zakupki@masterservice.ms',
            'password': 'master_service'

        }
        session.post('https://atg-ua.com.ua/login/', data=datas, headers=headers, params=None,
                     allow_redirects=True)
        session.post('https://atg-ua.com.ua/edit-account/', data=datas, headers=headers, params=None,
                     allow_redirects=True)
        session.post('https://atg-ua.com.ua/login/', data=datas, headers=headers, params=None,
                     allow_redirects=True)
        session.post('https://atg-ua.com.ua/edit-account/', data=datas, headers=headers, params=None,
                     allow_redirects=True)
        r = session.get(url, headers=headers, params=params)

        return r

    @staticmethod
    def save_file(items, path):
        with open(path, 'w', newline='', encoding='utf-8-sig') as file:
            writer = csv.writer(file, delimiter=';')
            writer.writerow(['id', 'Article', 'Description', 'Availability', 'Manufacturer', 'link', 'uah_price'])
            for item in items:
                writer.writerow([
                    item['id'],
                    item['title'],
                    item['Description'],
                    item['Availability'],
                    item['Manufacturer'],
                    item['link'],
                    item['uah_price']
                ])


class AtgParsAgregats(SamplePars):
    def __init__(self, url, name, pagination_cd):
        super().__init__(url, name, pagination_cd)

    def parser(self):
        attribute_pars = []
        if self.get_html(self.url).status_code == 200:
            for page in range(1, self.pagination_cd + 1):
                print(f'Scraping page {page}')
                html_save = self.get_html(self.url, params={'page': page})
                attribute_pars.extend(self.get_content(html_save.text))
            self.save_file(attribute_pars, self.CSV)
        else:
            print('Error')

    @staticmethod
    def get_content(html):
        items = BeautifulSoup(html, 'html.parser').find_all('div', class_='boxCategory_li')
        attribute = []
        for item in items:

            id = str(item.find('button', {'onclick': True}).get('onclick')[len("open_cart_modal('"):-len("');")]) \
                if item.find('button', {'onclick': True}).get('onclick') else "No"

            availability = 'No' if item.find \
                ('button', class_='sliderProduct_link disabled_button flex j-c_center a-i_center') else 'Yes'

            uah_price = item.find('i', class_='currenySymbol').previous_sibling.get_text(strip=True).replace \
                ('.', ',') if item.find('i', class_='currenySymbol') else item.find \
                ('div', class_='sliderProduct_boxPrice').get_text(strip=True)

            manufacturer = str(item.find('ul', class_='sliderProduct_description').find('span').next_sibling.get_text(
                strip=True)) if item.find('ul', class_='sliderProduct_description').find('span') else item.find(
                'ul', class_='sliderProduct_description').findNext().findNext().get_text(strip=True)

            attribute.append({
                'id': id,
                'title': item.find('p', class_='sliderProduct_article').get_text(strip=True),
                'Description': item.find('div', class_='sliderProduct_left').find('a').get_text(strip=True),
                'Availability': availability,
                'Manufacturer': manufacturer,
                'uah_price': uah_price,
                'link': item.find('a', class_='sliderProduct_thumb img-position').get('href'),
            })
        return attribute


class GurService(SamplePars):
    def __init__(self, url, name, pagination_cd):
        super().__init__(url, name, pagination_cd)

    def parser(self):
        attribute_pars = []
        if self.get_html(self.url).status_code == 200:
            for page in range(1, self.pagination_cd + 1):
                print(f'Scraping page {page}')
                url = self.url + "?page=" + str(page)
                print(url)
                html_save = self.get_html(url)
                attribute_pars.extend(self.get_content(html_save.text))
            self.save_file(attribute_pars, self.CSV)
        else:
            print('Error')

    @staticmethod
    def get_html(url, params=None, TLSAdapter=TLSAdapter):
        headers = {
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/111.0.0.0 Safari/537.36",
            "accept": "*/*"}
        session = requests.session()
        session.mount('https://', TLSAdapter())
        r = session.get(url, headers=headers)

        return r

    @staticmethod
    def get_content(html):
        items = BeautifulSoup(html, 'html.parser').find('div', class_='products-list-box').find_all('div',
                                                                                                    class_='item')
        attribute = []
        for item in items:
            availability = 'No' if (
                item.find('button', class_='sliderProduct_link disabled_button flex j-c_center a-i_center')) else 'Yes'
            title = item.find('span', class_='car-model').findNext().get_text(strip=True) if item.find('span',
                                                                                                       class_='car-model') else item.find(
                'a', class_='product-name').find('b').get_text(strip=True)
            attribute.append({
                'id': str(item.find('a', {'onclick': True}).get('onclick')),
                'title': title,
                'Availability': availability,
                'uah_price': item.find('div', class_='current-price').get_text(strip=True),
                'link': item.find('a', class_='').get('href'),
            })
        return attribute

    @staticmethod
    def save_file(items, path):
        with open(path, 'w', newline='', encoding='utf-8-sig') as file:
            writer = csv.writer(file, delimiter=',')
            writer.writerow(['Article', 'Availability', 'uah_price', 'link'])
            for item in items:
                writer.writerow([item['title'], item['Availability'], item['uah_price'], item['link']])


class –êpp_kiev(SamplePars):
    def __init__(self, url, name, pagination_cd):
        super().__init__(url, name, pagination_cd)

    def parser(self):
        attribute_pars = []
        if self.get_html(self.url).status_code == 200:
            for page in range(1, self.pagination_cd + 1):
                print(f'Scraping page {page}')
                url = self.url + "?PAGEN_1=" + str(page)
                print(url)
                html_save = self.get_html(url)
                attribute_pars.extend(self.get_content(html_save.text))
            self.save_file(attribute_pars, self.CSV)
        else:
            print('Error')

    @staticmethod
    def get_html(url, params=None):
        headers = {
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) "
                          "Chrome/108.0.0.0 Safari/537.36",
            "accept": "*/*"}
        r = requests.get(url, headers=headers)

        return r

    @staticmethod
    def get_content(html):
        global size_data
        items = BeautifulSoup(html, 'html.parser').find('div', class_='col-lg-9').find_all('li',
                                                                                           class_='list-group-item')
        attribute = []
        for item in items:
            availability = item.find('div', style='color: green').get_text(strip=True) if (
                item.find('div', style='color: green')) else 'no'

            if item.find('i', class_='fas fa-industry'):
                if not item.find('i', class_='fas fa-industry').findParent().findParent():
                    if not item.find('i', class_='fas fa-industry').findParent():
                        manufacturer = 'no'
                    else:
                        manufacturer = item.find('i', class_='fas fa-industry').findParent().get_text(
                            strip=True)
                else:
                    manufacturer = item.find('i', class_='fas fa-industry').findParent().findParent().get_text(
                        strip=True)
            else:
                manufacturer = 'no'

            if item.find('div', style="color: black"):
                if item.find('div', style="color: black").find('i', class_='fa-industry'):
                    size_data = 'no'
                else:
                    size_data = item.find('div', style="color: black").findNext().next_element.next_element.get_text(
                        strip=True)
            else:
                size_data = 'no'

            attribute.append({
                'title': item.find('h5', style='font-weight: bold;').find('a').get_text(strip=True),
                'Availability': availability,
                'Size': size_data,
                'Manufacturer': manufacturer,
                'uah_price': item.find('strong', class_='').get_text(strip=True).replace(' ', ''),
                'link': item.find('h5', style='font-weight: bold;').find('a', class_='').get('href'),
            })
        return attribute

    @staticmethod
    def save_file(items, path):
        with open(path, 'w', newline='', encoding='utf-8-sig') as file:
            writer = csv.writer(file, delimiter=',')
            writer.writerow(['Article', 'Availability', 'Size', 'Manufacturer', 'uah_price', 'link'])
            for item in items:
                writer.writerow(
                    [item['title'], item['Availability'], item['Size'], item['Manufacturer'], item['uah_price'],
                     item['link']])


def list_other_gur():
    object1 = AtgParsAgregats('https://atg-ua.com.ua/nasosy/gur', "GUR_pumps", 6)
    object1.parser()

    object3 = AtgParsAgregats('https://atg-ua.com.ua/rulevye-reyki/gidravlicheskie', "StGUR", 48)
    object3.parser()

    object4 = AtgParsAgregats('https://atg-ua.com.ua/rulevye-reyki/mehanicheskie', "StMEH", 12)
    object4.parser()


def list_other_eps():
    object1 = AtgParsAgregats('https://atg-ua.com.ua/nasosy/egur', "EPS_pumps", 5)
    object1.parser()

    object2 = AtgParsAgregats('https://atg-ua.com.ua/rulevye-reyki/elektricheskie', "StEPS", 13)
    object2.parser()

    object3 = AtgParsAgregats('https://atg-ua.com.ua/elektropidsilyuvachi', "ELB_EPS", 3)
    object3.parser()


def list_other_Seals():
    object4 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/c44-salniki', "Seals", 70)
    object4.parser()


def list_other_emmetec():
    # object1 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/c16-bachki-ta-krishki', "–ë–ê–ß–ö–ò_–ò_–ö–†–´–®–ö–ò", 2)
    # object1.parser()
    #
    # object2 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/c33-vali', "–í–ê–õ–´", 10)
    # object2.parser()
    #
    # object3 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/c15-datchiki-sensori-servotroniki',
    #                           "–î–ê–¢–ß–ò–ö–ò, –°–ï–ù–°–û–†–´, –°–ï–†–í–û", 3)
    # object3.parser()
    #
    # object4 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/zaglushki', "–ó–ê–ì–õ–£–®–ö–ò", 1)
    # object4.parser()
    #
    # object5 = AtgParsAgregats('https://atg-ua.com.ua/index.php?route=product/category&path=438_495', "–ó–ê–©–ò–¢–ù–´–ï –ö–†–´–®–ö–ò",
    #                           2)
    # object5.parser()
    #
    # object6 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/kolpachki', "–ö–û–õ–ü–ê–ß–ö–ò, –ó–ê–©–ò–¢–ù–´–ï –ú–ê–ù–ñ–ï–¢–´", 1)
    # object6.parser()
    #
    # object7 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/kolca-rezino-metal', "–ö–û–õ–¨–¶–ê –†–ï–ó–ò–ù–û-–ú–ï–¢–ê–õ", 1)
    # object7.parser()
    #
    # object8 = AtgParsAgregats('https://atg-ua.com.ua/index.php?route=product/category&path=438_497',
    #                           "–ö–û–ù–¢–ê–ö–¢–ù–ê–Ø –ì–†–£–ü–ü–ê, –†–ê–ó–¨–ï–ú–´", 3)
    # object8.parser()
    #
    # object9 = AtgParsAgregats('https://atg-ua.com.ua/index.php?route=product/category&path=438_496', "–ö–û–†–ü–£–°–ê", 3)
    # object9.parser()
    #
    # object10 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/krestoviny', "–ö–†–ï–°–¢–û–í–ò–ù–´", 1)
    # object10.parser()
    #
    # object11 = AtgParsAgregats('https://atg-ua.com.ua/index.php?route=product/category&path=438_498',
    #                            "–ú–û–¢–û–†–´, –†–ï–î–£–ö–¢–û–†–ê", 3)
    # object11.parser()
    #
    # object12 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/podshipniki', "–ü–û–î–®–ò–ü–ù–ò–ö–ò", 2)
    # object12.parser()
    #
    # object13 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/porshni', "–ü–û–†–®–ù–ò", 1)
    # object13.parser()
    #
    # object14 = AtgParsAgregats('https://atg-ua.com.ua/index.php?route=product/category&path=438_494', "–ü–†–û–í–û–î–ê", 1)
    # object14.parser()
    #
    # object15 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/pylniki-tyag', "–ü–´–õ–¨–ù–ò–ö–ò –¢–Ø–ì", 2)
    # object15.parser()
    #
    # object16 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/raznoe', "–†–ê–ó–ù–û–ï", 1)
    # object16.parser()
    #
    # object17 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/raspredelitel', "–†–ê–°–ü–†–ï–î–ï–õ–ò–¢–ï–õ–¨", 1)
    # object17.parser()
    #
    # object18 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/regulirovochnye-vtulki',
    #                            "–†–ï–ì–£–õ–ò–†–û–í–û–ß–ù–´–ï –í–¢–£–õ–ö–ò", 2)
    # object18.parser()
    #
    # object19 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/rezinovye-o-ring', "–†–ï–ó–ò–ù–û–í–´–ï O-RING", 8)
    # object19.parser()
    #
    # object20 = AtgParsAgregats('https://atg-ua.com.ua/index.php?route=product/category&path=438_493', "–†–ï–ú–ù–ò", 1)
    # object20.parser()
    #
    # object21 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/saylentbloki', "–°–ê–ô–õ–ï–ù–¢–ë–õ–û–ö–ò", 1)
    # object21.parser()
    #
    # object22 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/teflonovye-kolca', "–¢–ï–§–õ–û–ù–û–í–´–ï –ö–û–õ–¨–¶–ê", 4)
    # object22.parser()
    #
    # object23 = AtgParsAgregats('https://atg-ua.com.ua/index.php?route=product/category&path=438_492', "–¢–û–†–°–ò–û–ù–´", 2)
    # object23.parser()
    #
    # object24 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/trubki', "–¢–†–£–ë–ö–ò", 2)
    # object24.parser()
    #
    # object25 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/tyagi', "–¢–Ø–ì–ò", 1)
    # object25.parser()
    #
    # object26 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/uplotniteli-rezino-metall',
    #                            "–£–ü–õ–û–¢–ù–ò–¢–ï–õ–ò –†–ï–ó–ò–ù–û-–ú–ï–¢–ê–õ–õ", 2)
    # object26.parser()
    #
    # object27 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/fole-vstavka', "–§–û–õ–¨–ï –í–°–¢–ê–í–ö–ê", 2)
    # object27.parser()
    #
    # object28 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/homuty', "–•–û–ú–£–¢–´", 1)
    # object28.parser()
    #
    # object29 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/shayby', "–®–ê–ô–ë–´", 1)
    # object29.parser()
    #
    # object30 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/elektro-zapchasti', "–≠–õ–ï–ö–¢–†–û –ó–ê–ü–ß–ê–°–¢–ò", 1)
    # object30.parser()

    object31 = AtgParsAgregats('https://atg-ua.com.ua/komplektuyushchie/elektro-zapchasti', "–ö–û–ú–ü–õ–ï–ö–¢–£–Æ–ß–Ü", 283)
    object31.parser()


def list_other_nasosy_reyki():
    object6 = GurService('https://nasosy-reyki.com.ua/tovary/',
                         "GURS_other", 322)
    object6.parser()

    object6 = GurService('https://nasosy-reyki.com.ua/ru/tovary/rulevaya-reika/',
                         "GURS_reyki", 216)
    object6.parser()

    object6 = GurService('https://nasosy-reyki.com.ua/ru/tovary/nasosy/',
                         "GURS_nasosy", 101)
    object6.parser()


def list_other_–êpp_kiev():
    object1 = –êpp_kiev('https://app.kiev.ua/catalog/podshipniki/',
                       "–êpp_kiev_podshipniki", 1780)
    object1.parser()

    object2 = –êpp_kiev('https://app.kiev.ua/catalog/salniki/',
                       "–êpp_kiev_salniki", 1115)
    object2.parser()

    object3 = –êpp_kiev('https://app.kiev.ua/catalog/vtulki/',
                       "–êpp_kiev_vtulki", 23)
    object3.parser()

    object4 = –êpp_kiev('https://app.kiev.ua/catalog/koltsa_uplotnitelnye/',
                       "–êpp_kiev_koltsa_uplotnitelnye", 39)
    object4.parser()

    object5 = –êpp_kiev('https://app.kiev.ua/catalog/manzhety/',
                       "–êpp_kiev_manzhety", 3)
    object5.parser()

    object6 = –êpp_kiev('https://app.kiev.ua/catalog/shariki/',
                       "–êpp_kiev_shariki", 3)
    object6.parser()


def command_papser_subcategories_ATG():
    count = int(input())
    if count == 1:
        list_other_emmetec()
    elif count == 2:
        list_other_gur()
    elif count == 3:
        list_other_eps()
    elif count == 4:
        list_other_Seals()
    elif count == 5:
        list_other_nasosy_reyki()
    elif count == 6:
        list_other_–êpp_kiev()
    else:
        print("Not found")


command_papser_subcategories_ATG()
